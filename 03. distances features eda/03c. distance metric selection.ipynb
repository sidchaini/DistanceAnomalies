{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2cac55de-d790-41de-ab77-5f21a1d880aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T02:55:07.854396Z",
     "iopub.status.busy": "2025-05-13T02:55:07.853684Z",
     "iopub.status.idle": "2025-05-13T02:55:09.129162Z",
     "shell.execute_reply": "2025-05-13T02:55:09.128891Z",
     "shell.execute_reply.started": "2025-05-13T02:55:07.854379Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import os\n",
    "from sklearn.model_selection import cross_val_predict, train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, matthews_corrcoef\n",
    "import distclassipy as dcpy\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "os.chdir(\"../\")\n",
    "from pathlib import Path\n",
    "import matplotlib.gridspec as gridspec\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"scripts\")\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62d3b4c3-2136-4f60-934d-dfa1d1841e3a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T02:55:09.129705Z",
     "iopub.status.busy": "2025-05-13T02:55:09.129572Z",
     "iopub.status.idle": "2025-05-13T02:55:09.132903Z",
     "shell.execute_reply": "2025-05-13T02:55:09.132460Z",
     "shell.execute_reply.started": "2025-05-13T02:55:09.129696Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(\"settings.txt\") as f:\n",
    "    settings_dict = json.load(f)\n",
    "seed_val = settings_dict[\"seed_choice\"]\n",
    "np.random.seed(seed_val)\n",
    "sns_dict = settings_dict[\"sns_dict\"]\n",
    "sns.set_theme(**sns_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a936f3d6-84ea-4695-a2e0-47ff74e7ebf0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T02:55:09.133327Z",
     "iopub.status.busy": "2025-05-13T02:55:09.133243Z",
     "iopub.status.idle": "2025-05-13T02:55:09.137954Z",
     "shell.execute_reply": "2025-05-13T02:55:09.136771Z",
     "shell.execute_reply.started": "2025-05-13T02:55:09.133320Z"
    }
   },
   "outputs": [],
   "source": [
    "# custom_hues = [\"#3B4CC0\", \"#1FA187\", \"#FBAE17\", \"#D21F26\"]\n",
    "ibm_palette_hues = [\"#648FFF\", \"#785EF0\", \"#DC267F\", \"#FE6100\", \"#FFB000\"]\n",
    "# https://davidmathlogic.com/colorblind/\n",
    "sns.set_palette(ibm_palette_hues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0bcf863e-a588-4e70-9089-afae935891f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T02:55:09.139343Z",
     "iopub.status.busy": "2025-05-13T02:55:09.139033Z",
     "iopub.status.idle": "2025-05-13T02:55:09.144333Z",
     "shell.execute_reply": "2025-05-13T02:55:09.143144Z",
     "shell.execute_reply.started": "2025-05-13T02:55:09.139315Z"
    }
   },
   "outputs": [],
   "source": [
    "# all_metrics = settings_dict[\"all_metrics\"]\n",
    "all_metrics = dcpy._ALL_METRICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3eb86188-440a-42a0-97ea-cd8eec16e134",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T02:55:09.145210Z",
     "iopub.status.busy": "2025-05-13T02:55:09.145096Z",
     "iopub.status.idle": "2025-05-13T02:55:09.471224Z",
     "shell.execute_reply": "2025-05-13T02:55:09.470939Z",
     "shell.execute_reply.started": "2025-05-13T02:55:09.145200Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "EB      98473\n",
       "RRL     45096\n",
       "DSCT     8245\n",
       "CEP      1662\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced_features = pd.read_parquet(\"data/reduced_features.parquet\")\n",
    "reduced_features[\"class\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47eb954f-8a79-490f-b6f1-2b26b506dbf8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T02:55:09.473427Z",
     "iopub.status.busy": "2025-05-13T02:55:09.473353Z",
     "iopub.status.idle": "2025-05-13T02:55:09.496685Z",
     "shell.execute_reply": "2025-05-13T02:55:09.496331Z",
     "shell.execute_reply.started": "2025-05-13T02:55:09.473419Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: ['Power_rate_4', 'Harmonics_mag_5_Y', 'r-i', 'Multiband_period']\n"
     ]
    }
   ],
   "source": [
    "# n_cols = 5\n",
    "n_objs = 1000\n",
    "\n",
    "# 69% Features: ['Harmonics_phase_5_Y', 'Harmonics_mse_Y', 'Harmonics_mag_7_Y', 'Harmonics_phase_3_z', 'n_forced_phot_band_after_Y', 'Harmonics_phase_4_g', 'max_brightness_after_band_g', 'Harmonics_phase_2_z', 'Harmonics_phase_2_z', 'Harmonics_phase_3_z']\n",
    "# 65% Features: ['Harmonics_phase_6_r', 'Power_rate_4', 'Harmonics_mag_5_Y', 'Harmonics_phase_3_g', 'r-i']\n",
    "# 80% Features: ['Power_rate_4', 'Harmonics_mag_5_Y', 'Harmonics_phase_3_r', 'r-i']\n",
    "\n",
    "col_select = [\"Power_rate_4\", \"Harmonics_mag_5_Y\", \"r-i\", \"Multiband_period\"]\n",
    "print(f\"Features: {col_select}\")\n",
    "temp = reduced_features.loc[:, col_select + [\"class\"]].dropna()\n",
    "assert (temp[\"class\"].value_counts() > n_objs).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e2fd435-f19d-4c7a-8420-5f48d1143171",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T02:55:09.497259Z",
     "iopub.status.busy": "2025-05-13T02:55:09.497159Z",
     "iopub.status.idle": "2025-05-13T02:55:09.515656Z",
     "shell.execute_reply": "2025-05-13T02:55:09.515222Z",
     "shell.execute_reply.started": "2025-05-13T02:55:09.497251Z"
    }
   },
   "outputs": [],
   "source": [
    "temp = temp.groupby(\"class\").sample(n=n_objs)\n",
    "temp = temp.sample(frac=1, random_state=seed_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6c19a5f-3641-4f35-9b8a-d5486aff57ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T02:55:10.196692Z",
     "iopub.status.busy": "2025-05-13T02:55:10.195985Z",
     "iopub.status.idle": "2025-05-13T02:55:10.210161Z",
     "shell.execute_reply": "2025-05-13T02:55:10.208628Z",
     "shell.execute_reply.started": "2025-05-13T02:55:10.196661Z"
    }
   },
   "outputs": [],
   "source": [
    "X = temp[col_select].to_numpy()\n",
    "y = temp[\"class\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d258d0f3-62e2-4fce-baeb-dd629fd980f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T02:55:10.574569Z",
     "iopub.status.busy": "2025-05-13T02:55:10.573670Z",
     "iopub.status.idle": "2025-05-13T02:55:14.185244Z",
     "shell.execute_reply": "2025-05-13T02:55:14.184664Z",
     "shell.execute_reply.started": "2025-05-13T02:55:10.574511Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d06cb5fb61e44260a185232702ccd454",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Metric:   0%|          | 0/43 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_metric_dfs = {}\n",
    "all_metric_preds = {}\n",
    "\n",
    "for metric in tqdm(all_metrics, desc=\"Metric\", leave=True):\n",
    "    lcdc = dcpy.DistanceMetricClassifier(\n",
    "        scale=True,\n",
    "        central_stat=\"median\",\n",
    "        dispersion_stat=\"std\",\n",
    "    )\n",
    "    metric_str = utils.get_metric_name(metric)\n",
    "    lcdc.fit(X, y)\n",
    "    _ = lcdc.predict_and_analyse(X, metric=metric)\n",
    "\n",
    "    dist_df = lcdc.centroid_dist_df_\n",
    "    all_metric_dfs[metric_str] = dist_df\n",
    "\n",
    "    # Calculate preds for the current metric\n",
    "    class_names = [col.replace(\"_dist\", \"\") for col in dist_df.columns]\n",
    "    # Use .to_numpy() for robust operation with np.argmin\n",
    "    argmin_preds = np.argmin(dist_df.to_numpy(), axis=1)\n",
    "    preds = np.array([class_names[idx] for idx in argmin_preds])\n",
    "    all_metric_preds[metric_str] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c94f1d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T02:55:14.696897Z",
     "iopub.status.busy": "2025-05-13T02:55:14.696251Z",
     "iopub.status.idle": "2025-05-13T02:55:14.705547Z",
     "shell.execute_reply": "2025-05-13T02:55:14.704663Z",
     "shell.execute_reply.started": "2025-05-13T02:55:14.696851Z"
    }
   },
   "outputs": [],
   "source": [
    "# grouped_identical_dfs = []\n",
    "# processed_metric_names = set()\n",
    "\n",
    "# # Get a list of metric names to iterate over.\n",
    "# metric_names_list = list(all_metric_dfs.keys())\n",
    "\n",
    "# for i in range(len(metric_names_list)):\n",
    "#     name1 = metric_names_list[i]\n",
    "\n",
    "#     # If this metric has already been grouped with a previous one, skip it.\n",
    "#     if name1 in processed_metric_names:\n",
    "#         continue\n",
    "\n",
    "#     current_group = [name1]\n",
    "#     df1 = all_metric_dfs[name1]\n",
    "\n",
    "#     # Compare with subsequent metrics in the list.\n",
    "#     for j in range(i + 1, len(metric_names_list)):\n",
    "#         name2 = metric_names_list[j]\n",
    "\n",
    "#         # If this metric has already been grouped, skip it.\n",
    "#         if name2 in processed_metric_names:\n",
    "#             continue\n",
    "\n",
    "#         df2 = all_metric_dfs[name2]\n",
    "\n",
    "#         # DataFrame.equals() checks for identical content, shape, and dtypes.\n",
    "#         if df1.equals(df2):\n",
    "#             current_group.append(name2)\n",
    "#             # Mark name2 as processed since it's now part of current_group.\n",
    "#             processed_metric_names.add(name2)\n",
    "\n",
    "#     # Add name1 to processed_metric_names as it's now the representative of 'current_group'\n",
    "#     # (or forms a group of its own), preventing it from starting a new group.\n",
    "#     processed_metric_names.add(name1)\n",
    "#     grouped_identical_dfs.append(current_group)\n",
    "\n",
    "# # Filter for groups that have more than one metric (i.e., actual duplicates).\n",
    "# duplicate_groups = [group for group in grouped_identical_dfs if len(group) > 1]\n",
    "\n",
    "# if duplicate_groups:\n",
    "#     print(\"Metrics that produced identical centroid_dist_df_ DataFrames:\")\n",
    "#     for group in duplicate_groups:\n",
    "#         print(f\"- Metrics: {', '.join(group)}\")\n",
    "#         # As a quick check, you might want to see the shape of one of the identical DataFrames:\n",
    "#         # print(f\"  (Example DataFrame shape for this group: {all_metric_dfs[group[0]].shape})\")\n",
    "# else:\n",
    "#     print(\"All metrics produced unique centroid_dist_df_ DataFrames.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc11c980-2246-41bf-8264-4327f57bd1fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T02:55:15.306268Z",
     "iopub.status.busy": "2025-05-13T02:55:15.305460Z",
     "iopub.status.idle": "2025-05-13T02:55:15.315114Z",
     "shell.execute_reply": "2025-05-13T02:55:15.313320Z",
     "shell.execute_reply.started": "2025-05-13T02:55:15.306220Z"
    }
   },
   "outputs": [],
   "source": [
    "# # This code should be in a new cell, after the one modified above.\n",
    "# # It assumes 'all_metric_preds' is populated with metric names as keys\n",
    "# # and their corresponding prediction (preds) NumPy arrays as values.\n",
    "\n",
    "# grouped_identical_preds = []\n",
    "# processed_metric_names_for_preds = set()\n",
    "\n",
    "# # Get a list of metric names to iterate over.\n",
    "# metric_names_list_for_preds = list(all_metric_preds.keys())\n",
    "\n",
    "# for i in range(len(metric_names_list_for_preds)):\n",
    "#     name1 = metric_names_list_for_preds[i]\n",
    "    \n",
    "#     if name1 in processed_metric_names_for_preds:\n",
    "#         continue\n",
    "\n",
    "#     current_group_preds = [name1]\n",
    "#     preds1 = all_metric_preds[name1]\n",
    "\n",
    "#     for j in range(i + 1, len(metric_names_list_for_preds)):\n",
    "#         name2 = metric_names_list_for_preds[j]\n",
    "        \n",
    "#         if name2 in processed_metric_names_for_preds:\n",
    "#             continue\n",
    "\n",
    "#         preds2 = all_metric_preds[name2]\n",
    "        \n",
    "#         # Compare NumPy arrays for equality in both shape and element values.\n",
    "#         if np.array_equal(preds1, preds2):\n",
    "#             current_group_preds.append(name2)\n",
    "#             processed_metric_names_for_preds.add(name2)\n",
    "    \n",
    "#     processed_metric_names_for_preds.add(name1)\n",
    "#     grouped_identical_preds.append(current_group_preds)\n",
    "\n",
    "# # Filter for groups that have more than one metric (i.e., actual identical predictions).\n",
    "# duplicate_preds_groups = [group for group in grouped_identical_preds if len(group) > 1]\n",
    "\n",
    "# if duplicate_preds_groups:\n",
    "#     print(\"\\nMetrics that produced identical 'preds' arrays:\")\n",
    "#     for group in duplicate_preds_groups:\n",
    "#         print(f\"- Metrics: {', '.join(group)}\")\n",
    "#         # You could also print the length of the preds array for one of them as a check\n",
    "#         # if all_metric_preds[group[0]] is not None:\n",
    "#         #     print(f\"  (Example 'preds' array length for this group: {len(all_metric_preds[group[0]])})\")\n",
    "# else:\n",
    "#     print(\"\\nAll metrics produced unique 'preds' arrays.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b2cb371e-a533-4a26-9aa4-f7c0e7e8a0a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T02:55:15.700084Z",
     "iopub.status.busy": "2025-05-13T02:55:15.698798Z",
     "iopub.status.idle": "2025-05-13T02:55:16.072699Z",
     "shell.execute_reply": "2025-05-13T02:55:16.072437Z",
     "shell.execute_reply.started": "2025-05-13T02:55:15.700040Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics that produced identical DataFrames AFTER column-wise Min-Max normalization:\n",
      "- Metrics: Euclidean, Minkowski\n",
      "- Metrics: Braycurtis, Motyka, Czekanowski, Sorensen\n",
      "- Metrics: Cityblock, Gower\n",
      "- Metrics: Hellinger, Matusita\n",
      "- Metrics: Soergel, Ruzicka, Tanimoto\n",
      "- Metrics: Jensenshannon_Divergence, Jensen_Difference, Topsoe\n",
      "- Metrics: Prob_Chisq, Squared_Chisq\n"
     ]
    }
   ],
   "source": [
    "# This code should be in a new cell, after the one that populates 'all_metric_dfs'.\n",
    "# It assumes 'all_metric_dfs' contains the original (unnormalized) DataFrames.\n",
    "\n",
    "import numpy as np # Ensure numpy is imported\n",
    "\n",
    "def normalize_dataframe_columns(df):\n",
    "    \"\"\"Applies Min-Max normalization to each column of a DataFrame.\"\"\"\n",
    "    if df.empty:\n",
    "        return df\n",
    "    df_norm = df.copy()\n",
    "    for column in df_norm.columns:\n",
    "        min_val = df_norm[column].min()\n",
    "        max_val = df_norm[column].max()\n",
    "        if max_val - min_val == 0:\n",
    "            # If all values in a column are the same, scale to 0\n",
    "            # (or you could choose 0.5 or 1, depending on desired behavior for constant columns)\n",
    "            df_norm[column] = 0.0\n",
    "        else:\n",
    "            df_norm[column] = (df_norm[column] - min_val) / (max_val - min_val)\n",
    "    return df_norm\n",
    "\n",
    "grouped_identical_normalized_dfs = []\n",
    "processed_metric_names_norm = set()\n",
    "\n",
    "metric_names_list_norm = list(all_metric_dfs.keys())\n",
    "\n",
    "for i in range(len(metric_names_list_norm)):\n",
    "    name1 = metric_names_list_norm[i]\n",
    "    \n",
    "    if name1 in processed_metric_names_norm:\n",
    "        continue\n",
    "\n",
    "    current_group_norm = [name1]\n",
    "    df1_original = all_metric_dfs[name1]\n",
    "    \n",
    "    # Normalize df1 before comparison\n",
    "    # Ensure df1_original is not empty and has numeric types suitable for normalization\n",
    "    if df1_original.empty or not all(pd.api.types.is_numeric_dtype(df1_original[col]) for col in df1_original.columns):\n",
    "        # Skip problematic dataframes or handle as appropriate\n",
    "        # For now, let's print a warning and skip adding it to any group.\n",
    "        # print(f\"Warning: DataFrame for metric '{name1}' is empty or non-numeric, skipping normalization.\")\n",
    "        # processed_metric_names_norm.add(name1) # Mark as processed\n",
    "        # grouped_identical_normalized_dfs.append(current_group_norm) # Add it as a group of one\n",
    "        # continue # Or handle differently based on how you want to treat such cases\n",
    "        # For this implementation, we'll try to normalize and let it fail if types are wrong,\n",
    "        # or handle specific cases in normalize_dataframe_columns if needed.\n",
    "        # Given centroid_dist_df_ should be numeric, this might be an edge case.\n",
    "        pass\n",
    "\n",
    "    norm_df1 = normalize_dataframe_columns(df1_original.copy()) # Operate on a copy\n",
    "\n",
    "    for j in range(i + 1, len(metric_names_list_norm)):\n",
    "        name2 = metric_names_list_norm[j]\n",
    "        \n",
    "        if name2 in processed_metric_names_norm:\n",
    "            continue\n",
    "\n",
    "        df2_original = all_metric_dfs[name2]\n",
    "        if df2_original.empty or not all(pd.api.types.is_numeric_dtype(df2_original[col]) for col in df2_original.columns):\n",
    "            # Similar handling for df2\n",
    "            # print(f\"Warning: DataFrame for metric '{name2}' is empty or non-numeric, skipping normalization.\")\n",
    "            # continue\n",
    "            pass\n",
    "            \n",
    "        norm_df2 = normalize_dataframe_columns(df2_original.copy()) # Operate on a copy\n",
    "\n",
    "        # Compare shapes first, then use np.allclose for numerical arrays\n",
    "        if norm_df1.shape == norm_df2.shape and \\\n",
    "           np.allclose(norm_df1.to_numpy(dtype=float), norm_df2.to_numpy(dtype=float), equal_nan=True): # Added equal_nan=True\n",
    "            current_group_norm.append(name2)\n",
    "            processed_metric_names_norm.add(name2)\n",
    "    \n",
    "    processed_metric_names_norm.add(name1)\n",
    "    grouped_identical_normalized_dfs.append(current_group_norm)\n",
    "\n",
    "duplicate_normalized_groups = [group for group in grouped_identical_normalized_dfs if len(group) > 1]\n",
    "\n",
    "if duplicate_normalized_groups:\n",
    "    print(\"Metrics that produced identical DataFrames AFTER column-wise Min-Max normalization:\")\n",
    "    for group in duplicate_normalized_groups:\n",
    "        print(f\"- Metrics: {', '.join(group)}\")\n",
    "else:\n",
    "    print(\"All metrics produced unique DataFrames after column-wise Min-Max normalization.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a9fa7067-d049-43e4-867a-00edba338cb8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T02:55:17.278031Z",
     "iopub.status.busy": "2025-05-13T02:55:17.277196Z",
     "iopub.status.idle": "2025-05-13T02:55:17.289156Z",
     "shell.execute_reply": "2025-05-13T02:55:17.288252Z",
     "shell.execute_reply.started": "2025-05-13T02:55:17.277996Z"
    }
   },
   "outputs": [],
   "source": [
    "# dcpy.distances._ALL_METRICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e48cea33-fcbd-4dc5-96aa-6026297e84c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T02:55:18.681301Z",
     "iopub.status.busy": "2025-05-13T02:55:18.678706Z",
     "iopub.status.idle": "2025-05-13T02:55:18.707543Z",
     "shell.execute_reply": "2025-05-13T02:55:18.701648Z",
     "shell.execute_reply.started": "2025-05-13T02:55:18.681138Z"
    }
   },
   "outputs": [],
   "source": [
    "subset_metrics = ['euclidean',\n",
    " 'braycurtis',\n",
    " 'canberra',\n",
    " 'cityblock',\n",
    " 'chebyshev',\n",
    " 'clark',\n",
    " 'correlation',\n",
    " 'cosine',\n",
    " 'hellinger',\n",
    " 'jaccard',\n",
    " 'lorentzian',\n",
    " 'marylandbridge',\n",
    " 'meehl',\n",
    " # 'motyka',\n",
    " 'soergel',\n",
    " 'wave_hedges',\n",
    " 'kulczynski',\n",
    " 'add_chisq',\n",
    " 'acc',\n",
    " 'chebyshev_min',\n",
    " # 'czekanowski',\n",
    " 'dice',\n",
    " 'divergence',\n",
    " 'google',\n",
    " # 'gower',\n",
    " 'jeffreys',\n",
    " # 'jensenshannon_divergence',\n",
    " # 'jensen_difference',\n",
    " 'kumarjohnson',\n",
    " # 'matusita',\n",
    " # 'minkowski',\n",
    " 'penroseshape',\n",
    " # 'prob_chisq',\n",
    " # 'ruzicka',\n",
    " # 'sorensen',\n",
    " 'squared_chisq',\n",
    " 'squaredchord',\n",
    " 'squared_euclidean',\n",
    " 'taneja',\n",
    " # 'tanimoto',\n",
    " 'topsoe',\n",
    " 'vicis_symmetric_chisq',\n",
    " 'vicis_wave_hedges']\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
